{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5eb8df",
   "metadata": {},
   "source": [
    "## Model Train\n",
    "\n",
    "This notebook contains the process of training a model locally and saving metadata, training and evaluation metrics, as well as the artifacts to the public [W&B Experiment](https://wandb.ai/mikasenghaas/bsc?workspace=user-mikasenghaas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348489e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer\n",
    "\n",
    "# custom scripts\n",
    "from config import *\n",
    "from utils import *\n",
    "from model import MODELS, FinetunedImageClassifier\n",
    "from transform import ImageTransformer\n",
    "from data import ImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfefc4",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e64be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model args\n",
    "MODEL = \"resnet18\"\n",
    "PRETRAINED = True\n",
    "\n",
    "assert MODEL in MODELS, f\"Specified model has to be one of {list(MODELS.keys())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a337972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data args\n",
    "FILEPATH = PROCESSED_DATA_PATH\n",
    "INCLUDE_CLASSES = CLASSES\n",
    "RATIO = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b422a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training args\n",
    "MAX_EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "STEP_SIZE = 5\n",
    "GAMMA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b22405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify wand args\n",
    "WANDB_LOG = False\n",
    "WANDB_NAME = \"\"\n",
    "WANDB_GROUP = \"\"\n",
    "WANDB_TAGS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start run\n",
    "import wandb\n",
    "\n",
    "if WANDB_LOG:\n",
    "    wandb.init(\n",
    "        project=\"bsc\", \n",
    "        group=WANDB_GROUP if WANDB_GROUP else None, \n",
    "        name=WANDB_NAME if WANDB_NAME else None, \n",
    "        tags=WANDB_TAGS if WANDB_TAGS else None)\n",
    "\n",
    "    wandb.define_metric(\"training_loss\", summary=\"min\")\n",
    "    wandb.define_metric(\"validation_loss\", summary=\"min\")\n",
    "    wandb.define_metric(\"training_accuracy\", summary=\"max\")\n",
    "    wandb.define_metric(\"validation_accuracy\", summary=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77590adc",
   "metadata": {},
   "source": [
    "## Load Data, Transforms, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise data and loaders\n",
    "data = { split: ImageDataset(split=split, include_classes=INCLUDE_CLASSES, ratio=RATIO) for split in SPLITS } \n",
    "loader = { split: DataLoader(data[split], batch_size=BATCH_SIZE) for split in SPLITS}\n",
    "\n",
    "id2class, class2id = data[\"train\"].id2class, data[\"train\"].class2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6975bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise transforms\n",
    "transform = ImageTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model\n",
    "model = FinetunedImageClassifier(\n",
    "        model_name=MODEL,\n",
    "        num_classes=len(INCLUDE_CLASSES),\n",
    "        pretrained=PRETRAINED, \n",
    "        id2class=id2class,\n",
    "        class2id=class2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b96a9",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss, optimiser and lr scheduler\n",
    "criterion = nn.CrossEntropyLoss() # pyright: ignore\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, STEP_SIZE, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, transform, train_loader, val_loader, criterion, optim, scheduler):\n",
    "    model.to(DEVICE)\n",
    "    pbar = tqdm(range(MAX_EPOCHS))\n",
    "    pbar.set_description(f'XXX/XX (XX.Xms/ XX.Xms) - Train: X.XXX (XX.X%) - Val: X.XXX (XX.X%)')\n",
    "    train_loss, val_loss = 0.0, 0.0\n",
    "    train_acc, val_acc = 0.0, 0.0\n",
    "    training_times, inference_times = [], []\n",
    "    for epoch in pbar:\n",
    "        running_loss, running_correct = 0.0, 0\n",
    "        running_training_time, running_inference_time = 0.0, 0.0\n",
    "        model.train()\n",
    "        for batch_num, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "  \n",
    "            # zero the parameter gradients\n",
    "            optim.zero_grad()\n",
    "  \n",
    "            # forward pass\n",
    "            start = default_timer()\n",
    "            logits = model(transform(inputs))\n",
    "            running_inference_time += default_timer() - start\n",
    "\n",
    "            # compute predictions\n",
    "            preds = torch.argmax(logits, 1)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(logits, labels)\n",
    "  \n",
    "            # backprop error\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            running_training_time += default_timer() - start\n",
    "\n",
    "            # performance metrics\n",
    "            running_loss += loss.item()\n",
    "            running_correct += torch.sum(preds == labels)\n",
    "            samples_seen = (batch_num + 1) * BATCH_SIZE\n",
    "\n",
    "            # normalise\n",
    "            train_acc = running_correct / samples_seen\n",
    "            train_loss = running_loss / samples_seen\n",
    "            \n",
    "            pbar.set_description(f'{str(epoch).zfill(len(str(MAX_EPOCHS)))}/{str(batch_num).zfill(len(str(len(train_loader))))} ({round(running_training_time / samples_seen * 1000, 1)}ms | {round(running_inference_time / samples_seen * 1000, 1)}ms) - Train: {train_loss:.3f} ({(train_acc * 100):.1f}%) - Val: {val_loss:.3f} ({(val_acc * 100):.1f}%)')\n",
    "\n",
    "            # log epoch metrics for train and val split\n",
    "            if WANDB_LOG:\n",
    "                wandb.log({\n",
    "                    'training_accuracy': train_acc, \n",
    "                    'validation_accuracy': val_acc,\n",
    "                    'training_loss': train_loss, \n",
    "                    'validation_loss': val_loss})\n",
    "\n",
    "        training_times.append(running_training_time)\n",
    "        inference_times.append(running_inference_time)\n",
    "                \n",
    "        if val_loader != None:\n",
    "            running_loss, running_correct = 0.0, 0\n",
    "            model.eval()\n",
    "            for batch_num, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "      \n",
    "                logits = model(transform(inputs))\n",
    "                preds = torch.argmax(logits, 1)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                # accumulate loss and correct predictions\n",
    "                running_loss += loss.item()\n",
    "                running_correct += torch.sum(labels == preds)\n",
    "\n",
    "            val_loss = running_loss / len(val_loader.dataset)\n",
    "            val_acc = running_correct / len(val_loader.dataset)\n",
    "\n",
    "            pbar.set_description(f'{str(epoch).zfill(len(str(MAX_EPOCHS)))}/00 - Train: {train_loss:.3f} ({(train_acc * 100):.1f}%) - Val: {val_loss:.3f} ({(val_acc * 100):.1f}%)')\n",
    "\n",
    "        # adjust learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "    # log average training step time/ sample + inference time/ sample\n",
    "    if WANDB_LOG:\n",
    "        wandb.config.update({\n",
    "            \"training_time_per_sample_ms\" : round(sum(training_times) / len(training_times), 1),\n",
    "            \"inference_time_per_sample_ms\" : round(sum(inference_times) / len(inference_times), 1)\n",
    "            })\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a43431",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train(model, transform, loader[\"train\"], loader[\"val\"], criterion, optim, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fd046",
   "metadata": {},
   "source": [
    "## Example Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model in inference model\n",
    "trained_model.eval()\n",
    "trained_model.to('cpu')\n",
    "\n",
    "# load images from test split\n",
    "images, labels = next(iter(loader[\"test\"]))\n",
    "test_id2class = data[\"test\"].id2class\n",
    "\n",
    "# predict on images\n",
    "logits = trained_model(transform(images))\n",
    "probs = softmax(logits, 1)\n",
    "max_probs, preds = torch.max(probs, 1)\n",
    "\n",
    "# show images alongside true and predicted label\n",
    "show_images(images, titles=[f\"True: {test_id2class[labels[i].item()]}\\nPred: {id2class[preds[i].item()]}\" for i in range(len(labels))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
