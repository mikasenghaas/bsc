{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7h2F2QdCVsC"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFN9JCiSCX3y"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import *\n",
    "from config import *\n",
    "from data import ImageDataset, VideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise data splits\n",
    "data = { split: ImageDataset(split=split, include_classes=CLASSES, ratio=1.0) for split in SPLITS } \n",
    "id2class, class2id = data[\"train\"].id2class, data[\"train\"].class2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise data loaders\n",
    "loader = { split: DataLoader(data[split], BATCH_SIZE) for split in SPLITS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Disjointness of Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "for split in SPLITS:\n",
    "    paths[split] = set([path for path, _ in data[split].image_paths])\n",
    "\n",
    "for pair in combinations(SPLITS, 2):\n",
    "    fst, snd = pair\n",
    "    print(f\"{pair} has {len(paths[fst] & paths[snd])} images in common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Even Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(4*3,3))\n",
    "for i, split in enumerate(SPLITS):\n",
    "    dist = data[split].class_distribution\n",
    "    sns.barplot(x=list(dist.keys()), y=list(dist.values()), ax=ax[i])\n",
    "    ax[i].tick_params(axis='x', rotation=90)\n",
    "    ax[i].set(title=f\"{split.capitalize()} Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split\n",
    "images, labels = next(iter(loader[\"train\"]))\n",
    "\n",
    "show_images(images, titles=[id2class[l.item()] for l in labels], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val split\n",
    "images, labels = next(iter(loader[\"val\"]))\n",
    "\n",
    "show_images(images, titles=[id2class[l.item()] for l in labels], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test split\n",
    "images, labels = next(iter(loader[\"test\"]))\n",
    "\n",
    "show_images(images, titles=[id2class[l.item()] for l in labels], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VideoDataset.default_config()\n",
    "video_dataset = VideoDataset(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "clip, labels = video_dataset[random.randint(0, len(video_dataset))]\n",
    "image_tensors = [image for image in clip]\n",
    "\n",
    "# create a figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create an empty image object to hold the current frame\n",
    "im = ax.imshow(np.zeros_like(image_tensors[0].permute(1,2,0)))\n",
    "\n",
    "# define the update function that will be called for each frame\n",
    "def update(i):\n",
    "    im.set_data(image_tensors[i].permute(1, 2, 0))\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(image_tensors), interval=500, blit=True)\n",
    "\n",
    "ani.save('animation.mp4', writer='ffmpeg')\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(f'<video controls src=\"animation.mp4\" />')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clips\n",
    "len(video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only clips with 10 frames in length\n",
    "np.unique([len(clip) for clip, _ in video_dataset], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
